import streamlit as st
import time
import os
import uuid
from typing import TypedDict, List, Dict
from dotenv import load_dotenv
from PIL import Image
from moviepy import (
    ImageClip,
    VideoFileClip,
    AudioFileClip,
    TextClip,
    CompositeVideoClip,
    concatenate_videoclips
)
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langgraph.graph import StateGraph, END

from apiHeygen import HeygenAPI
from apiKlingAI import KlingAIAPI
import requests
import base64

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# --- 1. ê¸°ë³¸ ì„¤ì • ë° API í‚¤ ì…ë ¥ ---
# .env íŒŒì¼ì—ì„œ OpenRouter API í‚¤ ë¡œë“œ

openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
if openrouter_api_key:
    os.environ["OPENAI_API_KEY"] = openrouter_api_key
else:
    raise RuntimeError(
        "Missing OPENROUTER_API_KEY. Set it in your environment or .env file (OPENROUTER_API_KEY=...)."
    )

# ì„ì‹œ íŒŒì¼ë“¤ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±
if not os.path.exists("temp"):
    os.makedirs("temp")

# --- 2. LangGraph ìƒíƒœ ì •ì˜ ---
# ê° ì—ì´ì „íŠ¸ê°€ ì‘ì—… ë‚´ìš©ì„ ê³µìœ í•˜ëŠ” ë°ì´í„° êµ¬ì¡°
class AgentState(TypedDict):
    theme: str
    script: str
    image_paths: List[str]
    audio_path: str
    total_duration: int
    storyboard: List[Dict]  # ì‹œë‚˜ë¦¬ì˜¤ ì‘ê°€ì˜ ê²°ê³¼ë¬¼ (ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, ê¸¸ì´ ë“±)
    subtitle_clips: List[VideoFileClip]  # ìë§‰ì´ í¬í•¨ëœ í´ë¦½ ë¦¬ìŠ¤íŠ¸
    final_video_path: str   # ìµœì¢… ì œì‘ìì˜ ê²°ê³¼ë¬¼ (ì™„ì„±ëœ ì˜ìƒ ê²½ë¡œ)
    error_message: str      # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë©”ì‹œì§€ ì €ì¥
    generated_video_paths: List[str]  # image_video_generator_agentê°€ ìƒì„±í•œ ë¹„ë””ì˜¤ ê²½ë¡œë“¤

# --- 3. ì—ì´ì „íŠ¸ ë° ë„êµ¬(Tool) ì •ì˜ ---
    """
    ê° ì—ì´ì „íŠ¸ëŠ” íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ë©°, ìƒíƒœ ì—…ë°ì´íŠ¸
    - 3.1. ì‹œë‚˜ë¦¬ì˜¤ ì‘ê°€ ì—ì´ì „íŠ¸: ìŠ¤í¬ë¦½íŠ¸ì™€ ì´ë¯¸ì§€ ê°œìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±
    - 3.2. ì´ë¯¸ì§€-ë¹„ë””ì˜¤ ìƒì„± ì—ì´ì „íŠ¸: ì‚¬ìš©ì ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ì…˜ ë¹„ë””ì˜¤ ìƒì„±
    - 3.3. ìë§‰ ìƒì„± ì—ì´ì „íŠ¸: ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìë§‰ ì˜ìƒ ìƒì„±
    - 3.4. ìµœì¢… ì œì‘ì ì—ì´ì „íŠ¸: ê¸°ì¡´ ì˜ìƒê³¼ ìë§‰ ì˜ìƒì„ ê²°í•©í•˜ì—¬ ìµœì¢… ì˜ìƒ ì œì‘
    """

# 3.1. ì‹œë‚˜ë¦¬ì˜¤ ì‘ê°€ ì—ì´ì „íŠ¸ (Scenario Writer Agent)
def scenario_writer_agent(state: AgentState):
    """ìŠ¤í¬ë¦½íŠ¸ì™€ ì´ë¯¸ì§€ ê°œìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    st.write("### ğŸ¤µ ì‹œë‚˜ë¦¬ì˜¤ ì‘ê°€ ì—ì´ì „íŠ¸")
    st.info("ì…ë ¥ëœ ìŠ¤í¬ë¦½íŠ¸ì™€ ì‚¬ì§„ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì˜ìƒì˜ ì „ì²´ íë¦„ì„ ê¸°íší•˜ê³  ìˆìŠµë‹ˆë‹¤...")

    theme = state["theme"]
    script = state["script"]
    num_images = len(state["image_paths"])
    total_duration = state["total_duration"]

    # LLM ëª¨ë¸ ì •ì˜
    llm = ChatOpenAI(
        model="openai/gpt-5-nano",
        temperature=0.5,
        base_url="https://openrouter.ai/api/v1",
        default_headers={
            "HTTP-Referer": os.getenv("YOUR_SITE_URL", ""),
            "X-Title": os.getenv("YOUR_SITE_NAME", ""),
        }
    )

    # LLMì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """ë‹¹ì‹ ì€ ê°ë™ì ì¸ ì¶”ëª¨ ì˜ìƒì„ ìœ„í•œ ì‹œë‚˜ë¦¬ì˜¤ ì‘ê°€ì…ë‹ˆë‹¤.
                ì‚¬ìš©ìì˜ 7ê°œ ì¥ë©´ìœ¼ë¡œ êµ¬ì„±ëœ ìŠ¤í¬ë¦½íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê° ì¥ë©´ì˜ ë‚´ìš©ê³¼ ê¸¸ì´ë¥¼ JSON í˜•ì‹ì˜ ìŠ¤í† ë¦¬ë³´ë“œ(storyboard)ë¡œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.
                
                ì‚¬ìš©ìì˜ ìŠ¤í¬ë¦½íŠ¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ 7ê°œë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:
                1. "ë‚´ê°€ ê°€ì¥ í–‰ë³µí–ˆì„ ë•ŒëŠ”"
                2. ì‚¬ìš©ì ììœ  ì…ë ¥
                3. ì‚¬ìš©ì ììœ  ì…ë ¥  
                4. "ì—¬ë³´,"
                5. ì‚¬ìš©ì ììœ  ì…ë ¥
                6. ì‚¬ìš©ì ììœ  ì…ë ¥
                7. "ì§€ê¸ˆ, ì„ ë¬¼"
                
                - ì „ì²´ ì˜ìƒ ê¸¸ì´ëŠ” ë°˜ë“œì‹œ {total_duration}ì´ˆê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
                - ê° ì¥ë©´ì€ 10ì´ˆ, 10ì´ˆ, 10ì´ˆ, 5ì´ˆ, 10ì´ˆ, 10ì´ˆ, 12ì´ˆë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
                - ê° ì¥ë©´(scene)ì€ 'image_index', 'duration', 'subtitle' í‚¤ë§Œ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.
                - 'image_index'ëŠ” ìˆœì„œëŒ€ë¡œ 1, 2, 3, 4, 5, 6, 7ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
                - 'duration'ì€ í•´ë‹¹ ì¥ë©´ì˜ ì´ˆ ë‹¨ìœ„ ê¸¸ì´ì…ë‹ˆë‹¤. ëª¨ë“  durationì˜ í•©ì€ {total_duration}ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
                - narration, visual_cue, music_cue ë“±ì˜ ì¶”ê°€ í•„ë“œëŠ” ì ˆëŒ€ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.
                - í…Œë§ˆ '{theme}'ì˜ ë¶„ìœ„ê¸°ë¥¼ ë°˜ì˜í•´ì£¼ì„¸ìš”.
                - ìµœì¢… ì¶œë ¥ì€ ì˜¤ì§ JSON ê°ì²´ë§Œ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
                """,
            ),
            (
                "human",
                "ì‚¬ìš©ì ìŠ¤í¬ë¦½íŠ¸: {script}\n"
            ),
        ]
    )
    
    # JSON ì¶œë ¥ì„ ìœ„í•œ íŒŒì„œ
    parser = JsonOutputParser()

    # ì²´ì¸ êµ¬ì„±
    chain = prompt | llm | parser

    try:
        storyboard_data = chain.invoke({
            "total_duration": total_duration,
            "num_images": num_images,
            "theme": theme,
            "script": script,
        })
        
        # storyboard_dataê°€ Noneì¸ì§€ í™•ì¸
        if storyboard_data is None:
            error_msg = "OpenAI APIë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            st.error(error_msg)
            return {"error_message": error_msg}
        
        # 'storyboard' í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì¶”ì¶œ
        if isinstance(storyboard_data, dict) and 'storyboard' in storyboard_data:
            storyboard = storyboard_data['storyboard']
        elif isinstance(storyboard_data, dict) and 'scenes' in storyboard_data:
            # 'scenes' í‚¤ê°€ ìˆëŠ” ê²½ìš°ë„ ì²˜ë¦¬
            storyboard = storyboard_data['scenes']
        elif isinstance(storyboard_data, list):
            # ì§ì ‘ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜ëœ ê²½ìš°
            storyboard = storyboard_data
        else:
            # ë”•ì…”ë„ˆë¦¬ì´ì§€ë§Œ storyboardë‚˜ scenes í‚¤ê°€ ì—†ëŠ” ê²½ìš°, ê°’ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì‹œë„
            if isinstance(storyboard_data, dict):
                # ë”•ì…”ë„ˆë¦¬ì˜ ê°’ë“¤ì´ scene ê°ì²´ë“¤ì¸ì§€ í™•ì¸
                values = list(storyboard_data.values())
                if values and all(isinstance(v, dict) and 'image_index' in v for v in values):
                    storyboard = values
                else:
                    storyboard = storyboard_data
            else:
                storyboard = storyboard_data

        # storyboardê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ ìµœì¢… í™•ì¸
        if not isinstance(storyboard, list):
            error_msg = f"ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íƒ€ì…: {type(storyboard)}, ë‚´ìš©: {storyboard}"
            st.error(error_msg)
            return {"error_message": error_msg}

        # storyboard duration ì§€ì •
        durations = [10, 10, 10, 5, 10, 10, 12]
        if len(storyboard) == len(durations):
            for i in range(len(storyboard)):
                if isinstance(storyboard[i], dict):
                    storyboard[i]['duration'] = durations[i]
        
        st.success("ìŠ¤í† ë¦¬ë³´ë“œ ê¸°íš ì™„ë£Œ!")
        # ë””ë²„ê¹…ì„ ìœ„í•´ ìŠ¤í† ë¦¬ë³´ë“œ ì¶œë ¥
        with st.expander("ìƒì„±ëœ ìŠ¤í† ë¦¬ë³´ë“œ ë³´ê¸°"):
            st.json(storyboard)

        return {"storyboard": storyboard}
    
    except Exception as e:
        error_msg = f"ì‹œë‚˜ë¦¬ì˜¤ ì‘ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        st.error(error_msg)
        return {"error_message": error_msg}

# 3.2. ì´ë¯¸ì§€-ë¹„ë””ì˜¤ ìƒì„± ì—ì´ì „íŠ¸ (Image Video Generator Agent) 
def image_video_generator_agent(state: AgentState):
    """ì‚¬ìš©ì ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ HeyGenê³¼ KlingAIë¥¼ ì‚¬ìš©í•´ ëª¨ì…˜ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    st.write("### ğŸ¨ ì´ë¯¸ì§€-ë¹„ë””ì˜¤ ìƒì„± ì—ì´ì „íŠ¸")
    st.info("ì—…ë¡œë“œëœ ì‚¬ì§„ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì›€ì§ì´ëŠ” ì˜ìƒì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
    
    image_paths = state.get("image_paths")
    theme = state.get("theme")
    
    if not image_paths:
        error_msg = "ì´ë¯¸ì§€-ë¹„ë””ì˜¤ ìƒì„±ì— í•„ìš”í•œ ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤."
        st.error(error_msg)
        return {"error_message": error_msg}
    
    heygen_api_key = os.getenv("HEYGEN_API_KEY")
    kling_ak = os.getenv("AK")
    kling_sk = os.getenv("SK")
    
    use_original_images = False
    if not heygen_api_key:
        st.warning("HeyGen API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        use_original_images = True
    elif not kling_ak or not kling_sk:
        st.warning("KlingAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        use_original_images = True
    
    generated_video_paths = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, image_path in enumerate(image_paths):
        try:
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = (idx + 1) / len(image_paths)
            progress_bar.progress(progress)
            status_text.text(f"ì´ë¯¸ì§€ {idx + 1}/{len(image_paths)} ì²˜ë¦¬ ì¤‘...")
            
            enhanced_image_path = image_path  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì›ë³¸ ì´ë¯¸ì§€ ì„¤ì •
            video_creation_success = False
            
            if not use_original_images:
                try:
                    st.write(f"HeyGenìœ¼ë¡œ ì´ë¯¸ì§€ {idx + 1} ì²˜ë¦¬ ì¤‘...")
                    heygen = HeygenAPI(heygen_api_key)
                    heygen_result = heygen.generate_avatar_photo(
                        image_path=image_path,
                        name=f"Person_{idx+1}",
                        age="Late Middle Age",
                        gender="Person",
                        ethnicity="East Asian",
                        orientation="horizontal",
                        pose="half_body",
                        style="Realistic",
                        appearance="A headshot of a person with a gentle smile. Clean white background. Professional and warm expression."
                    )
                    
                    if heygen_result.get("data") and heygen_result["data"].get("generation_id"):
                        generation_id = heygen_result["data"]["generation_id"]
                        max_wait_time = 300  # 5ë¶„ ëŒ€ê¸°
                        wait_time = 0
                        
                        while wait_time < max_wait_time:
                            status = heygen.check_generation_status(generation_id)
                            if status.get("data") and status["data"].get("status") == "success":
                                image_urls = status["data"].get("image_url_list", [])
                                if image_urls:
                                    img_resp = requests.get(image_urls[0])
                                    if img_resp.status_code == 200:
                                        enhanced_image_path = f"temp/enhanced_image_{idx+1}_{uuid.uuid4()}.jpg"
                                        with open(enhanced_image_path, "wb") as f:
                                            f.write(img_resp.content)
                                        st.success(f"HeyGen ì´ë¯¸ì§€ {idx + 1} ìƒì„± ì™„ë£Œ")
                                        break
                            time.sleep(5)  
                            wait_time += 5
                        else:
                            st.warning(f"HeyGen ì´ë¯¸ì§€ {idx + 1} ìƒì„± ì‹œê°„ ì´ˆê³¼, ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©")
                    
                    st.write(f"KlingAIë¡œ ë¹„ë””ì˜¤ {idx + 1} ìƒì„± ì¤‘...")
                    
                    with open(enhanced_image_path, "rb") as img_file:
                        img_base64 = base64.b64encode(img_file.read()).decode("utf-8")
                    
                    klingai = KlingAIAPI(kling_ak, kling_sk)
                    video_data = {
                        "model_name": "kling-v2-1",
                        "mode": "pro",
                        "duration": "10",
                        "image": img_base64,  
                        "prompt": f"Create a gentle, moving video from this memorial photo. {theme} style. Soft, warm lighting with subtle camera movement. The person in the photo should have a gentle, peaceful expression.",
                        "cfg_scale": 0.5,
                    }
                    
                    init_response = klingai.generate_video(video_data)
                    task_data = init_response.get("data", {})
                    task_id = task_data.get("task_id")
                    
                    if not task_id:
                        st.warning(f"KlingAI ë¹„ë””ì˜¤ {idx + 1} ìƒì„± ìš”ì²­ ì‹¤íŒ¨, ì •ì  ì´ë¯¸ì§€ ì‚¬ìš©")
                    else:
                        st.write(f"KlingAI ì‘ì—… ID: {task_id}")
                        
                        max_wait = 600  # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (10ë¶„)
                        interval = 15   # í´ë§ ê°„ê²© (15ì´ˆ)
                        start_time = time.time()
                        
                        while time.time() - start_time < max_wait:
                            status_response = klingai.check_task_status(task_id)
                            poll_data = status_response.get("data", {})
                            poll_status = poll_data.get("task_status")
                            
                            st.write(f"KlingAI ìƒíƒœ: {poll_status}")
                            
                            if poll_status == "succeed":
                                videos = poll_data.get("task_result", {}).get("videos", [])
                                if videos:
                                    video_url = videos[0].get("url")
                                    st.success(f"KlingAI ë¹„ë””ì˜¤ {idx + 1} ìƒì„± ì„±ê³µ!")
                                    
                                    video_response = requests.get(video_url, stream=True)
                                    video_response.raise_for_status()
                                    
                                    video_path = f"temp/generated_video_{idx+1}_{uuid.uuid4()}.mp4"
                                    with open(video_path, "wb") as f:
                                        for chunk in video_response.iter_content(chunk_size=8192):
                                            f.write(chunk)
                                    
                                    generated_video_paths.append(video_path)
                                    st.success(f"KlingAI ë¹„ë””ì˜¤ {idx + 1} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                                    video_creation_success = True
                                    break
                                else:
                                    st.warning(f"KlingAI ë¹„ë””ì˜¤ {idx + 1} ì •ë³´ê°€ ì‘ë‹µì— í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
                                    break
                            
                            elif poll_status == "failed":
                                fail_msg = poll_data.get("task_status_msg", "ì‹¤íŒ¨ ì‚¬ìœ  ì•Œ ìˆ˜ ì—†ìŒ")
                                if "risk control" in fail_msg.lower():
                                    st.info(f"KlingAI ì½˜í…ì¸  ì •ì±…ìœ¼ë¡œ ì¸í•´ ë¹„ë””ì˜¤ {idx + 1} ìƒì„±ì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤. ì •ì  ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                                else:
                                    st.warning(f"KlingAI ë¹„ë””ì˜¤ {idx + 1} ìƒì„± ì‹¤íŒ¨: {fail_msg}")
                                break
                                
                            time.sleep(interval)
                        else:
                            st.warning(f"KlingAI ë¹„ë””ì˜¤ {idx + 1} ìƒì„± ì‹œê°„ ì´ˆê³¼, ì •ì  ì´ë¯¸ì§€ ì‚¬ìš©")
                
                except Exception as api_error:
                    error_msg = str(api_error)
                    if "insufficient_quota" in error_msg or "402" in error_msg:
                        st.warning(f"API í• ë‹¹ëŸ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                        use_original_images = True
                    else:
                        st.warning(f"API ì˜¤ë¥˜ ë°œìƒ: {error_msg}. ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
            if not video_creation_success or use_original_images:
                st.write(f"ì •ì  ë¹„ë””ì˜¤ {idx + 1} ìƒì„± ì¤‘...")
                try:
                    video_clip = ImageClip(enhanced_image_path).with_duration(10)
                    video_path = f"temp/static_video_{idx+1}_{uuid.uuid4()}.mp4"
                    video_clip.write_videofile(video_path, codec="libx264", fps=24)
                    generated_video_paths.append(video_path)
                    st.success(f"ì •ì  ë¹„ë””ì˜¤ {idx + 1} ìƒì„± ì™„ë£Œ")
                except Exception as video_error:
                    st.error(f"ë¹„ë””ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {video_error}")
                    try:
                        video_clip = ImageClip(image_path).with_duration(10)
                        video_path = f"temp/fallback_video_{idx+1}_{uuid.uuid4()}.mp4"
                        video_clip.write_videofile(video_path, codec="libx264", fps=24)
                        generated_video_paths.append(video_path)
                        st.warning(f"ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë¹„ë””ì˜¤ {idx + 1} ìƒì„± ì™„ë£Œ")
                    except Exception as final_error:
                        error_msg = f"ì´ë¯¸ì§€ {idx + 1} ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {final_error}"
                        return {"error_message": error_msg}
            
        except Exception as e:
            st.error(f"ì´ë¯¸ì§€ {idx + 1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            try:
                video_clip = ImageClip(image_path).with_duration(10)
                video_path = f"temp/fallback_video_{idx+1}_{uuid.uuid4()}.mp4"
                video_clip.write_videofile(video_path, codec="libx264", fps=24)
                generated_video_paths.append(video_path)
                st.warning(f"ì˜¤ë¥˜ ë³µêµ¬: ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë¹„ë””ì˜¤ {idx + 1} ìƒì„± ì™„ë£Œ")
            except:
                error_msg = f"ì´ë¯¸ì§€ {idx + 1} ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}"
                return {"error_message": error_msg}
    
    if not generated_video_paths:
        error_msg = "ìƒì„±ëœ ë¹„ë””ì˜¤ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤."
        st.error(error_msg)
        return {"error_message": error_msg}
    
    if use_original_images:
        st.success(f"ì´ {len(generated_video_paths)}ê°œì˜ ì •ì  ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ! (ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©)")
    else:
        st.success(f"ì´ {len(generated_video_paths)}ê°œì˜ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
    
    return {"generated_video_paths": generated_video_paths}

# 3.3. ìë§‰ ìƒì„± ì—ì´ì „íŠ¸ (Subtitle Creator Agent) 
def subtitle_creator_agent(state: AgentState):
    """ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ëª…í•œ ë°°ê²½ì˜ ìë§‰ ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤."""
    st.write("### ğŸ“ ìë§‰ ìƒì„± ì—ì´ì „íŠ¸")
    st.info("ì…ë ¥ëœ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ì¥ë©´ì— ë“¤ì–´ê°ˆ ìë§‰ ì˜ìƒì„ ë§Œë“¤ê³  ìˆìŠµë‹ˆë‹¤...")
    
    script_lines = state.get("script").split("\n")
    storyboard = state.get("storyboard")
    
    if not storyboard or not script_lines:
        error_msg = "ìë§‰ ìƒì„±ì— í•„ìš”í•œ ì •ë³´(ìŠ¤í† ë¦¬ë³´ë“œ, ìŠ¤í¬ë¦½íŠ¸)ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
        st.error(error_msg)
        return {"error_message": error_msg}
    
    # ë””ë²„ê¹…ì„ ìœ„í•´ storyboard íƒ€ì…ê³¼ ë‚´ìš© í™•ì¸
    st.write(f"Storyboard type in subtitle creator: {type(storyboard)}")
    st.write(f"Storyboard content: {storyboard}")
    
    # storyboardê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
    if not isinstance(storyboard, list):
        error_msg = f"ìŠ¤í† ë¦¬ë³´ë“œê°€ ì˜ˆìƒëœ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. í˜„ì¬ íƒ€ì…: {type(storyboard)}"
        st.error(error_msg)
        return {"error_message": error_msg}

    # í°íŠ¸ ê²½ë¡œ ì„¤ì • 
    font_path = "resources/font/movie-font.ttf"
    if not os.path.exists(font_path):
        error_msg = f"ì§€ì •ëœ í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {font_path}"
        st.error(error_msg)
        return {"error_message": error_msg}
    
    subtitle_clips = []
    
    for idx, scene in enumerate(storyboard):
        try:
            if (idx + 1) in [1, 4, 7]:
                subtitle_clips.append(None)
                continue
            
            text = script_lines[idx].strip()
            
            if not isinstance(scene, dict):
                st.error(f"ì¥ë©´ {idx+1}ì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤. íƒ€ì…: {type(scene)}, ë‚´ìš©: {scene}")
                continue
            
            if 'duration' not in scene:
                st.error(f"ì¥ë©´ {idx+1}ì— 'duration' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. í‚¤ë“¤: {list(scene.keys())}")
                continue
                
            duration = scene['duration']
            
            # ê¸°ë³¸ TextClip ìƒì„±
            main_text_clip = TextClip(
                text=text,
                font_size=40,
                color='white',
                font=font_path,
                transparent=True
            ).with_duration(duration).with_position(("center", 810), relative=False)

            # ê·¸ë¦¼ì íš¨ê³¼ë¥¼ ìœ„í•œ TextClip ìƒì„±
            shadow_text_clip = TextClip(
                text=text,
                font_size=40,
                color='black',
                font=font_path,
                transparent=True
            ).with_duration(duration).with_position(("center", 815), relative=False)  
            
            # ë‘ í´ë¦½ì„ í•©ì³ì„œ í•˜ë‚˜ì˜ ìë§‰ í´ë¦½ìœ¼ë¡œ ë§Œë“¦
            subtitle_clip = CompositeVideoClip([shadow_text_clip, main_text_clip], size=(1920, 1080))
        
            subtitle_clips.append(subtitle_clip)
            
        except IndexError:
            st.warning(f"ìŠ¤í¬ë¦½íŠ¸ ë¬¸í•­ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì¥ë©´ {idx+1}ì˜ ìë§‰ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
            subtitle_clips.append(None)
            continue
        except Exception as e:
            st.error(f"ìë§‰ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"error_message": f"ìë§‰ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}

    if not any(subtitle_clips): 
        error_msg = "ìë§‰ì„ êµ¬ì„±í•  ì¥ë©´ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤."
        st.error(error_msg)
        return {"error_message": error_msg}
    
    st.success("ìë§‰ í´ë¦½ ìƒì„± ì™„ë£Œ!")
    
    # ê° ì¥ë©´ë³„ë¡œ ìƒì„±ëœ í´ë¦½ë“¤ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
    return {"subtitle_clips": subtitle_clips}

# 3.4. ìµœì¢… ì œì‘ì ì—ì´ì „íŠ¸ (Final Producer Agent) 
def final_producer_agent(state: AgentState):
    """ê¸°ì¡´ ì˜ìƒê³¼ ìë§‰ ì˜ìƒì„ ê²°í•©í•˜ì—¬ ìµœì¢… ì˜ìƒì„ ì œì‘í•©ë‹ˆë‹¤."""
    st.write("### ğŸ¬ ìµœì¢… ì œì‘ì ì—ì´ì „íŠ¸")
    st.info("ê¸°íšëœ ìŠ¤í† ë¦¬ë³´ë“œì— ë”°ë¼ ì‚¬ì§„, ìë§‰, ìŒì„±ì„ í•©ì³ ìµœì¢… ì˜ìƒì„ ë§Œë“¤ê³  ìˆìŠµë‹ˆë‹¤...")
    
    storyboard = state.get("storyboard")
    image_paths = state.get("image_paths")
    audio_path = state.get("audio_path")
    subtitle_clips = state.get("subtitle_clips")
    generated_video_paths = state.get("generated_video_paths", [])
    
    # í…Œë§ˆë³„ íš¨ê³¼ ì„¤ì •
    # ì´ ë¶€ë¶„ì„ í™•ì¥í•˜ì—¬ ë” ë‹¤ì–‘í•œ íš¨ê³¼ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    def apply_theme_effects(clip, duration):
        # Effects ì‚¬ìš©ì„ ì œê±°í•˜ê³  ê¸°ë³¸ í´ë¦½ ë°˜í™˜
        return clip

    # ë””ë²„ê¹…ì„ ìœ„í•´ storyboard íƒ€ì…ê³¼ ë‚´ìš© í™•ì¸
    st.write(f"Storyboard type: {type(storyboard)}")
    st.write(f"Storyboard content: {storyboard}")
    
    # storyboardê°€ ë¬¸ìì—´ì¸ ê²½ìš° JSONìœ¼ë¡œ íŒŒì‹±
    if isinstance(storyboard, str):
        import json
        try:
            storyboard = json.loads(storyboard)
        except json.JSONDecodeError:
            st.error("ìŠ¤í† ë¦¬ë³´ë“œ íŒŒì‹± ì˜¤ë¥˜: JSON í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return {"error_message": "ìŠ¤í† ë¦¬ë³´ë“œ íŒŒì‹± ì˜¤ë¥˜"}
    
    # ê° ì¥ë©´ë³„ë¡œ ê¸°ë³¸ ì˜ìƒê³¼ ìë§‰ì„ í•©ì„±í•  ë¦¬ìŠ¤íŠ¸
    combined_clips = []
    
    # ì§„í–‰ë¥  ë° ì‹œê°„ í‘œì‹œë¥¼ ìœ„í•œ ì„¤ì •
    total_scenes = len(storyboard)
    start_time = time.time()

    # ì§„í–‰ë¥  í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()
    time_text = st.empty()

    # ì˜ˆìƒ ì‹œê°„ ê³„ì‚° (ì¥ë©´ë‹¹ í‰ê·  3ì´ˆë¡œ ê°€ì •)
    estimated_total_time = total_scenes * 3

    for scene_idx, scene in enumerate(storyboard):
        try:
            # ë¨¼ì € ì¥ë©´ ë°ì´í„° ì¶”ì¶œ
            img_index = scene['image_index']
            duration = scene['duration']

            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = (scene_idx + 1) / total_scenes
            progress_bar.progress(progress)

            # ìƒíƒœ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            status_text.text(f"ì¥ë©´ {scene_idx + 1}/{total_scenes} ì²˜ë¦¬ ì¤‘...")

            # ê²½ê³¼ ì‹œê°„ ë° ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
            elapsed_time = time.time() - start_time
            if scene_idx > 0:
                avg_time_per_scene = elapsed_time / scene_idx
                remaining_scenes = total_scenes - scene_idx
                estimated_remaining_time = avg_time_per_scene * remaining_scenes

                time_text.text(f"â±ï¸ ê²½ê³¼ ì‹œê°„: {elapsed_time:.0f}ì´ˆ | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining_time:.0f}ì´ˆ")
            else:
                time_text.text(f"â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„: {estimated_total_time}ì´ˆ")

            video_clip = None
            
            if img_index == 1:
                video_clip = VideoFileClip("resources/theme/t01.mp4").with_duration(duration)
            elif img_index == 2:
                if len(generated_video_paths) > 0 and os.path.exists(generated_video_paths[0]):
                    video_clip = VideoFileClip(generated_video_paths[0]).with_duration(duration)
                elif len(image_paths) > 0:
                    # ë°±ì—…: ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                    video_clip = ImageClip(image_paths[0]).with_duration(duration)
                else:
                    st.warning("ì¥ë©´ 2ì— í•„ìš”í•œ ì‚¬ì§„ì´ ì—†ì–´ ê¸°ë³¸ í´ë¦½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    video_clip = VideoFileClip("resources/theme/t01.mp4").with_duration(duration)
            elif img_index == 3:
                if len(generated_video_paths) > 1 and os.path.exists(generated_video_paths[1]):
                    video_clip = VideoFileClip(generated_video_paths[1]).with_duration(duration)
                elif len(image_paths) > 1:
                    # ë°±ì—…: ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                    video_clip = ImageClip(image_paths[1]).with_duration(duration)
                else:
                    st.warning("ì¥ë©´ 3ì— í•„ìš”í•œ ì‚¬ì§„ì´ ì—†ì–´ ê¸°ë³¸ í´ë¦½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    video_clip = VideoFileClip("resources/theme/t01.mp4").with_duration(duration)
            elif img_index == 4:
                video_clip = VideoFileClip("resources/theme/t04.mp4").with_duration(duration)
            elif img_index == 5:
                if len(generated_video_paths) > 2 and os.path.exists(generated_video_paths[2]):
                    video_clip = VideoFileClip(generated_video_paths[2]).with_duration(duration)
                elif len(image_paths) > 2:
                    # ë°±ì—…: ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                    video_clip = ImageClip(image_paths[2]).with_duration(duration)
                else:
                    st.warning("ì¥ë©´ 5ì— í•„ìš”í•œ ì‚¬ì§„ì´ ì—†ì–´ ê¸°ë³¸ í´ë¦½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    video_clip = VideoFileClip("resources/theme/t01.mp4").with_duration(duration)
            elif img_index == 6:
                if len(generated_video_paths) > 3 and os.path.exists(generated_video_paths[3]):
                    video_clip = VideoFileClip(generated_video_paths[3]).with_duration(duration)
                elif len(image_paths) > 3:
                    # ë°±ì—…: ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                    video_clip = ImageClip(image_paths[3]).with_duration(duration)
                else:
                    st.warning("ì¥ë©´ 6ì— í•„ìš”í•œ ì‚¬ì§„ì´ ì—†ì–´ ê¸°ë³¸ í´ë¦½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    video_clip = VideoFileClip("resources/theme/t01.mp4").with_duration(duration)
            elif img_index == 7:
                video_clip = VideoFileClip("resources/theme/ending.mp4").with_duration(duration)
            else:
                st.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì´ë¯¸ì§€ ì¸ë±ìŠ¤ {img_index}. ê¸°ë³¸ í´ë¦½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                video_clip = VideoFileClip("resources/theme/t01.mp4").with_duration(duration)
            
            if video_clip:
                video_clip = video_clip.resized(height=1080)
            
            final_scene_clip = video_clip
            
            # ì‚­ì œ: 1, 4, 7ë²ˆì§¸ ìë§‰ì´ Noneì´ë¯€ë¡œ, í•´ë‹¹ í´ë¦½ì´ ìˆì„ ë•Œë§Œ í•©ì„±
            if subtitle_clips and len(subtitle_clips) > scene_idx and subtitle_clips[scene_idx] is not None:
                current_subtitle_clip = subtitle_clips[scene_idx]
                final_scene_clip = CompositeVideoClip([video_clip, current_subtitle_clip])
            
            if final_scene_clip:
                combined_clips.append(final_scene_clip)

        # í…Œë§ˆ ì ìš©
        #video_clip = apply_theme_effects(video_clip, duration)                
        #clips.append(video_clip)
        
        except Exception as e:
            st.error(f"ì¥ë©´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"error_message": f"ì¥ë©´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}

    if not combined_clips:
        error_msg = "ì˜ìƒì„ êµ¬ì„±í•  ì¥ë©´ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤."
        st.error(error_msg)
        return {"error_message": error_msg}

    # ëª¨ë“  ì˜ìƒ í´ë¦½ì„ í•˜ë‚˜ë¡œ ì—°ê²°
    final_video_clip = concatenate_videoclips(combined_clips, method="compose")

    # ë°±ê·¸ë¼ìš´ë“œ ìŒì•… ì¶”ê°€
    background_music_path = "resources/music/m0.mp3"
    if os.path.exists(background_music_path):
        background_music = AudioFileClip(background_music_path)

        # ë°°ê²½ìŒì•…ì„ ì˜ìƒ ê¸¸ì´ì— ë§ê²Œ ì¡°ì •
        if background_music.duration < final_video_clip.duration:
            # ìŒì•…ì´ ì§§ìœ¼ë©´ ë°˜ë³µ
            loops_needed = int(final_video_clip.duration / background_music.duration) + 1
            background_music = background_music.loop(loops_needed)

        # ìŒì•…ì„ ì˜ìƒ ê¸¸ì´ì— ë§ê²Œ ìë¥´ê¸°
        background_music = background_music.subclipped(0, final_video_clip.duration)

        # ë°°ê²½ìŒì•… ë³¼ë¥¨ ì¡°ì ˆ - MoviePy ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•´ ê°„ë‹¨í•˜ê²Œ ì²˜ë¦¬
        background_music = background_music.with_fps(22050)
        # ë³¼ë¥¨ ì¡°ì ˆì€ ì˜¤ë””ì˜¤ ë¯¹ì‹± ì‹œ CompositeAudioClipì—ì„œ ì²˜ë¦¬

        if audio_path:
            # ì‚¬ìš©ì ìŒì„±ì´ ìˆìœ¼ë©´ ë¯¹ì‹±
            user_audio = AudioFileClip(audio_path)
            if user_audio.duration > final_video_clip.duration:
                user_audio = user_audio.subclipped(0, final_video_clip.duration)

            # ë‘ ì˜¤ë””ì˜¤ë¥¼ í•©ì„± (ë°°ê²½ìŒì•… + ì‚¬ìš©ì ìŒì„±)
            from moviepy import CompositeAudioClip
            # ë°°ê²½ìŒì•…ê³¼ ì‚¬ìš©ì ìŒì„±ì„ ë¯¹ì‹± (ë°°ê²½ìŒì•…ì€ ìë™ìœ¼ë¡œ ë‚®ì€ ë³¼ë¥¨)
            mixed_audio = CompositeAudioClip([background_music, user_audio])
            final_video_clip = final_video_clip.with_audio(mixed_audio)
        else:
            # ì‚¬ìš©ì ìŒì„±ì´ ì—†ìœ¼ë©´ ë°°ê²½ìŒì•…ë§Œ
            final_video_clip = final_video_clip.with_audio(background_music)
    else:
        # ë°°ê²½ìŒì•… íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë¡œì§
        if audio_path:
            audio_clip = AudioFileClip(audio_path)
            if audio_clip.duration > final_video_clip.duration:
                audio_clip = audio_clip.subclipped(0, final_video_clip.duration)
            final_video_clip = final_video_clip.with_audio(audio_clip)

    output_filename = f"temp/final_video_{uuid.uuid4()}.mp4"
    final_video_clip.write_videofile(output_filename, codec="libx264", audio_codec="aac", fps=24)
    
    st.success("ì˜ìƒ ì œì‘ ì™„ë£Œ!")
    return {"final_video_path": output_filename}

# --- 4. LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„± ---
workflow = StateGraph(AgentState)

workflow.add_node("scenario_writer", scenario_writer_agent)
workflow.add_node("image_video_generator", image_video_generator_agent)  
workflow.add_node("subtitle_creator", subtitle_creator_agent)
workflow.add_node("final_producer", final_producer_agent)

workflow.set_entry_point("scenario_writer")
workflow.add_edge("scenario_writer", "image_video_generator")  
workflow.add_edge("image_video_generator", "subtitle_creator") 
workflow.add_edge("subtitle_creator", "final_producer") 
workflow.add_edge("final_producer", END) 

# ê·¸ë˜í”„ ì»´íŒŒì¼
app = workflow.compile()

# --- 5. Streamlit UI êµ¬ì„± ---
st.set_page_config(page_title="ğŸ•Šï¸ ì¶”ëª¨ ì˜ìƒ ì œì‘ ì—ì´ì „íŠ¸", layout="wide")

st.title("ğŸ•Šï¸ ì¶”ëª¨ ì˜ìƒ ì œì‘ ì—ì´ì „íŠ¸")
st.markdown("ê³ ì¸ì„ ê¸°ë¦¬ëŠ” ì†Œì¤‘í•œ ë§ˆìŒì„ ë‹´ì•„, ì„¸ìƒì— í•˜ë‚˜ë¿ì¸ ì˜ìƒì„ ë§Œë“¤ì–´ ë“œë¦½ë‹ˆë‹¤.")
st.markdown("---")

col1, col2 = st.columns(2)

with col1:
    st.subheader("1. ì˜ìƒ ì •ë³´ ì…ë ¥")
    
    theme = st.selectbox(
        "ì˜ìƒ í…Œë§ˆ ì„ íƒ",
        ["ë”°ëœ»í•œ ì¶”ì–µ (Warm Memories)", "ì°¨ë¶„í•œ íšŒìƒ (Calm Reflection)", "ì‚¶ì˜ ì¶•í•˜ (Celebrating a Life)"],
        help="ì˜ìƒ ì „ì²´ì˜ ë¶„ìœ„ê¸°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."
    )

    st.subheader("ì˜ìƒì— ë‹´ì„ ê¸€ ì…ë ¥ (7ê°œ ë¬¸í•­)")
    
    # 7ê°œì˜ ê³ ì •/ììœ  ì…ë ¥ í•„ë“œ
    text_inputs = []
    
    # ì²« ë²ˆì§¸ í•„ë“œ (ê³ ì • - ì…ë ¥ í•„ë“œ ì—†ìŒ)
    st.write("**ì¥ë©´ #1. ë‚´ê°€ ê°€ì¥ í–‰ë³µí–ˆì„ ë•ŒëŠ”**")
    text_inputs.append("ë‚´ê°€ ê°€ì¥ í–‰ë³µí–ˆì„ ë•ŒëŠ”")
    
    # ë‘ ë²ˆì§¸ í•„ë“œ (ììœ ì…ë ¥)
    text_inputs.append(st.text_input("**ì¥ë©´ #2.** ë‘ ë²ˆì§¸ ë¬¸ì¥", key="text2", value="ë‚´ ë‚˜ì´ 76ì„¸, í‰ìƒ ê³µë¶€í•˜ê³  ì‹¶ë˜, ëŒ€í•™êµë¥¼ ì¡¸ì—…í–ˆì„ ë•Œ."))
    
    # ì„¸ ë²ˆì§¸ í•„ë“œ (ììœ ì…ë ¥)
    text_inputs.append(st.text_input("**ì¥ë©´ #3.** ì„¸ ë²ˆì§¸ ë¬¸ì¥", key="text3", value="ì‘ì›í•´ ì¤€, ìš°ë¦¬ ë”¸ ë§ì´ ì‚¬ë‘í•´"))
    
    # ë„¤ ë²ˆì§¸ í•„ë“œ (ê³ ì • - ì…ë ¥ í•„ë“œ ì—†ìŒ)
    st.write("**ì¥ë©´ #4. ì—¬ë³´,**")
    text_inputs.append("ì—¬ë³´,")
    
    # ë‹¤ì„¯ ë²ˆì§¸ í•„ë“œ (ììœ ì…ë ¥)
    text_inputs.append(st.text_input("**ì¥ë©´ #5.** ë‹¤ì„¯ ë²ˆì§¸ ë¬¸ì¥", key="text5", value="í‰ìƒ ë‚˜ì™€ ì‚´ë©´ì„œ ê³ ìƒ ë§ì•˜ì–´"))
    
    # ì—¬ì„¯ ë²ˆì§¸ í•„ë“œ (ììœ ì…ë ¥)
    text_inputs.append(st.text_input("**ì¥ë©´ #6.** ì—¬ì„¯ ë²ˆì§¸ ë¬¸ì¥", key="text6", value="í•­ìƒ ê³ ë§™ê³ , ì¦ê²ê³  í–‰ë³µí•œ ì‚¶ì„ ì‚´ì•˜ìœ¼ë©´ ì¢‹ê² ë‹¤. ê³ ë§™ë‹¤."))
    
    # ì¼ê³± ë²ˆì§¸ í•„ë“œ (ê³ ì • - ì…ë ¥ í•„ë“œ ì—†ìŒ)
    st.write("**ì¥ë©´ #7. ì§€ê¸ˆ, ì„ ë¬¼**")
    text_inputs.append("ì§€ê¸ˆ, ì„ ë¬¼")
    
    # ì „ì²´ í…ìŠ¤íŠ¸ ì¡°í•©
    script = "\n".join([text for text in text_inputs if text.strip()])

    st.subheader("ì‚¬ì§„ ì—…ë¡œë“œ (4ì¥)")
    uploaded_images = []
    
    # 1ë²ˆì§¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ í•„ë“œ
    st.write("**ì¥ë©´ #2 ì‚¬ì§„**")
    col_upload1, col_thumb1 = st.columns([2, 1])
    
    with col_upload1:
        img1 = st.file_uploader(
            "ì¥ë©´ #2 ì‚¬ì§„ ì„ íƒ",
            type=["jpg", "jpeg", "png"],
            key="image_1",
            help="ê³ í™”ì§ˆ ì‚¬ì§„ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
        )
    
    with col_thumb1:
        if img1 is not None:
            image1 = Image.open(img1)
            st.image(image1, width=100, caption="ì¥ë©´ #2 ì‚¬ì§„")

    # 2ë²ˆì§¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ í•„ë“œ
    st.write("**ì¥ë©´ #3 ì‚¬ì§„**")
    col_upload2, col_thumb2 = st.columns([2, 1])
    
    with col_upload2:
        img2 = st.file_uploader(
            "ì¥ë©´ #3 ì‚¬ì§„ ì„ íƒ",
            type=["jpg", "jpeg", "png"],
            key="image_2",
            help="ê³ í™”ì§ˆ ì‚¬ì§„ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
        )
    
    with col_thumb2:
        if img2 is not None:
            image2 = Image.open(img2)
            st.image(image2, width=100, caption="ì¥ë©´ #3 ì‚¬ì§„")

    # 3ë²ˆì§¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ í•„ë“œ
    st.write("**ì¥ë©´ #5 ì‚¬ì§„**")
    col_upload3, col_thumb3 = st.columns([2, 1])
    
    with col_upload3:
        img3 = st.file_uploader(
            "ì¥ë©´ #5 ì‚¬ì§„ ì„ íƒ",
            type=["jpg", "jpeg", "png"],
            key="image_3",
            help="ê³ í™”ì§ˆ ì‚¬ì§„ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
        )
    
    with col_thumb3:
        if img3 is not None:
            image3 = Image.open(img3)
            st.image(image3, width=100, caption="ì¥ë©´ #5 ì‚¬ì§„")
    
    # 4ë²ˆì§¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ í•„ë“œ
    st.write("**ì¥ë©´ #6 ì‚¬ì§„**")
    col_upload4, col_thumb4 = st.columns([2, 1])
    
    with col_upload4:
        img4 = st.file_uploader(
            "ì¥ë©´ #6 ì‚¬ì§„ ì„ íƒ",
            type=["jpg", "jpeg", "png"],
            key="image_4",
            help="ê³ í™”ì§ˆ ì‚¬ì§„ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
        )
    
    with col_thumb4:
        if img4 is not None:
            image4 = Image.open(img4)
            st.image(image4, width=100, caption="ì¥ë©´ #6 ì‚¬ì§„")
    
    # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë“¤ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (Noneì´ ì•„ë‹Œ ê²ƒë§Œ)
    for img in [img1, img2, img3, img4]:
        if img is not None:
            uploaded_images.append(img)

    uploaded_audio = st.file_uploader(
        "ìŒì„± íŒŒì¼ ì—…ë¡œë“œ",
        type=["mp3", "wav", "m4a"],
        help="ì˜ìƒ ì „ì²´ì— ì‚¬ìš©ë  ìŒì› íŒŒì¼ì…ë‹ˆë‹¤. 70ì´ˆ ì´í•˜ ê¸¸ì´ì˜ íŒŒì¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
    )

with col2:
    st.subheader("2. ì˜ìƒ ìƒì„± ë° í™•ì¸")
    
    if st.button("ğŸ¥ ì˜ìƒ ì œì‘ ì‹œì‘í•˜ê¸°", type="primary"):
        # ì…ë ¥ ê°’ ê²€ì¦
        validation_errors = []
        # ìµœì†Œ 3ê°œ ì´ìƒì˜ í•„ë“œê°€ ì…ë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
        filled_inputs = [text for text in text_inputs if len(text.strip()) > 0]
        if len(filled_inputs) < 3:
            validation_errors.append("ìµœì†Œ 3ê°œ ì´ìƒì˜ ë¬¸í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        #if not uploaded_images:
        #    validation_errors.append("ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        if validation_errors:
            for error in validation_errors:
                st.error(error)
        elif not os.getenv("OPENAI_API_KEY"):
            st.error(".env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("AI ì—ì´ì „íŠ¸ë“¤ì´ ì˜ìƒ ì œì‘ì„ ì‹œì‘í•©ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                # 1. ì„ì‹œ íŒŒì¼ ì €ì¥
                temp_image_paths = []
                for img_file in uploaded_images:
                    img = Image.open(img_file)
                    file_path = f"temp/{uuid.uuid4()}.png"
                    img.save(file_path)
                    temp_image_paths.append(file_path)

                temp_audio_path = None
                if uploaded_audio:
                    temp_audio_path = f"temp/{uuid.uuid4()}.mp3"
                    with open(temp_audio_path, "wb") as f:
                        f.write(uploaded_audio.getbuffer())

                # 2. ì—ì´ì „íŠ¸ ì´ˆê¸° ìƒíƒœ ì„¤ì •
                initial_state = AgentState(
                    theme=theme,
                    script=script,
                    image_paths=temp_image_paths,
                    audio_path=temp_audio_path,
                    total_duration=67, # ì´ ì˜ìƒ ê¸¸ì´ ê³ ì •
                    storyboard=None,
                    final_video_path=None,
                    error_message=None,
                    subtitle_clips=[],
                    generated_video_paths=[] 
                )
                
                # 3. LangGraph ì‹¤í–‰
                final_state = app.invoke(initial_state)

                # 4. ê²°ê³¼ ì²˜ë¦¬
                if final_state.get("error_message"):
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {final_state['error_message']}")
                else:
                    video_path = final_state.get("final_video_path")
                    
                    if video_path and os.path.exists(video_path):
                        st.subheader("âœ¨ ì˜ìƒì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤ âœ¨")
                        st.video(video_path)
                        
                        with open(video_path, "rb") as file:
                            st.download_button(
                                label="ì˜ìƒ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                                data=file,
                                file_name="memorial_video.mp4",
                                mime="video/mp4"
                            )
                            
                        st.markdown("---")
                        if st.button("ì„ì‹œ íŒŒì¼ ì •ë¦¬í•˜ê¸°", help="ë‹¤ìš´ë¡œë“œ í›„ ì´ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì„ì‹œ íŒŒì¼ì„ ì‚­ì œí•˜ì„¸ìš”."):
                            if os.path.exists(video_path): os.remove(video_path)
                            for path in temp_image_paths:
                                if os.path.exists(path): os.remove(path)
                            generated_videos = final_state.get("generated_video_paths", [])
                            for video_path in generated_videos:
                                if os.path.exists(video_path): os.remove(video_path)
                            if temp_audio_path and os.path.exists(temp_audio_path) and temp_audio_path != "resources/music/m0.mp3":
                                 os.remove(temp_audio_path)
                            st.success("ì„ì‹œ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

                    else:
                        st.error("ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ë¡œ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# --- UI í•˜ë‹¨ ì„¤ëª… ì¶”ê°€ ---
st.markdown("---")